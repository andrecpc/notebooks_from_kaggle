{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"subs_csi_train = pd.read_csv('../input/subs_csi_train.csv')\nsubs_csi_test = pd.read_csv('../input/subs_csi_test.csv')\nsubs_features_train = pd.read_csv('../input/subs_features_train.csv', decimal=b',')\nsubs_features_test = pd.read_csv('../input/subs_features_test.csv', decimal=b',')\nsubs_bs_consumption_train = pd.read_csv('../input/subs_bs_consumption_train.csv', decimal=b',')\nsubs_bs_consumption_test = pd.read_csv('../input/subs_bs_consumption_test.csv', decimal=b',')\n# subs_bs_data_session_train = pd.read_csv('../input/subs_bs_data_session_train.csv', decimal=b',')\n# subs_bs_data_session_test = pd.read_csv('../input/subs_bs_data_session_test.csv', decimal=b',')\nsubs_bs_voice_session_train = pd.read_csv('../input/subs_bs_voice_session_train.csv', decimal=b',')\nsubs_bs_voice_session_test = pd.read_csv('../input/subs_bs_voice_session_test.csv', decimal=b',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74bfe6109f687ebe3927162980d0b3f7449d136a"},"cell_type":"code","source":"categorical_columns_features_train = ['SK_ID','COM_CAT#1', 'COM_CAT#3', 'BASE_TYPE', 'ACT', 'ARPU_GROUP', 'COM_CAT#7', 'DEVICE_TYPE_ID', 'INTERNET_TYPE_ID', 'COM_CAT#25', 'COM_CAT#26', 'COM_CAT#34']\nprint (len(subs_features_train[categorical_columns_features_train]))\ncat_cols = []\nfor col in categorical_columns_features_train:\n    cat_cols.append( str((col,\" : \",len(subs_features_train[col].unique()),'\\n')))\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ed750f5133342eaf9a93e064ef6560b6ccc1229"},"cell_type":"code","source":"from collections import Counter\nget_most_common = lambda values: max(Counter(values).items(), key = lambda x: x[1])[0]\nsubs_features_train_cat = subs_features_train[categorical_columns_features_train].groupby(['SK_ID']).agg(get_most_common).reset_index()\nsubs_features_test_cat = subs_features_test[categorical_columns_features_train].groupby(['SK_ID']).agg(get_most_common).reset_index()\nsubs_features_test_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eef581ffae93c34060c4cc9dcb2def791f739b5b"},"cell_type":"code","source":"num_cols = ['SK_ID','COM_CAT#2', 'COM_CAT#8','REVENUE','ITC','VAS','RENT_CHANNEL','ROAM','COST','COM_CAT#17','COM_CAT#18','COM_CAT#19','COM_CAT#20','COM_CAT#21','COM_CAT#22','COM_CAT#23','COM_CAT#27','COM_CAT#28','COM_CAT#29','COM_CAT#30','COM_CAT#31','COM_CAT#32','COM_CAT#33']\nsubs_features_train_num = subs_features_train[num_cols].groupby('SK_ID').agg('sum').reset_index()\nsubs_features_test_num = subs_features_test[num_cols].groupby('SK_ID').agg('sum').reset_index()\nsubs_features_test_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"450206bfb605dac46af8367b77ca42e0ff367564"},"cell_type":"code","source":"\nimport calendar\nprint (subs_csi_test.CONTACT_DATE.unique(),subs_csi_train.CONTACT_DATE.unique())\ndays = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\nformat = lambda x: days[calendar.weekday(2018,int(str(x)[3:]),int(str(x)[0:2]))] if len(str(x))==5 else days[calendar.weekday(2018,int(str(x)[3:]),int('0'+str(x)[0:1]))]\nsubs_csi_test['DAY'] = subs_csi_test['CONTACT_DATE'].map(format)\nsubs_csi_train['DAY'] = subs_csi_train['CONTACT_DATE'].map(format)\nsubs_csi_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5b2670b45f36ce3e6bed62af29409061d76549fe"},"cell_type":"code","source":"# categorical_columns_train = [c for c in subs_bs_consumption_train.columns if subs_bs_consumption_train[c].dtype.name == 'object']\n# numerical_columns_train = [c for c in subs_bs_consumption_train.columns if subs_bs_consumption_train[c].dtype.name != 'object']\n# print (categorical_columns_train)\n# print (numerical_columns_train)\nsubs_bs_consumption_train = subs_bs_consumption_train[['SK_ID','SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN']].groupby('SK_ID').agg('mean').reset_index()\nsubs_bs_consumption_test = subs_bs_consumption_test[['SK_ID','SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN']].groupby('SK_ID').agg('mean').reset_index()\n\nsubs_bs_voice_session_train = subs_bs_voice_session_train[['SK_ID','VOICE_DUR_MIN']].groupby('SK_ID').agg('mean').reset_index()\nsubs_bs_voice_session_test = subs_bs_voice_session_test[['SK_ID','VOICE_DUR_MIN']].groupby('SK_ID').agg('mean').reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ad621a391c64b52704075585839c0511eb8b238"},"cell_type":"code","source":"Train = pd.merge(subs_bs_consumption_train, subs_csi_train, on='SK_ID', how='outer')\nTrain = pd.merge(subs_bs_voice_session_train, Train, on='SK_ID', how='outer')\nTrain = pd.merge(subs_features_train_num, Train, on='SK_ID', how='outer')\nTrain = pd.merge(subs_features_train_cat, Train, on='SK_ID', how='outer')\nTrain = Train.dropna(subset=['SUM_MINUTES'])\nTrain = Train.dropna(subset=['VOICE_DUR_MIN'])\nTrain = Train.fillna(0)\n\nTest = pd.merge(subs_csi_test, subs_bs_consumption_test,on='SK_ID', how='outer')\nTest = pd.merge(Test, subs_bs_voice_session_test,on='SK_ID', how='outer')\nTest = pd.merge(Test, subs_features_test_num,on='SK_ID', how='outer')\nTest = pd.merge(Test, subs_features_test_cat,on='SK_ID', how='outer')\nTest = Test.fillna(0)\n# Test = Test[['SK_ID','CONTACT_DATE','SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN','VOICE_DUR_MIN','DAY']]\nprint (Test.columns)\nTest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a893b39e25cdcabec95093b9236324c9c5c6e4a"},"cell_type":"code","source":"cats = [cat for cat in categorical_columns_features_train if cat not in ['SK_ID']]\nprint (cats)\ndef OHE(cols,df):\n    for col in cols:\n        s = df[col].unique()\n        print (s)\n\n        # Create a One Hot Dataframe with 1 row for each unique value\n        one_hot_df = pd.get_dummies(s, prefix='%s_' % col)\n        one_hot_df[col] = s\n\n        print(\"Adding One Hot values for %s (the column has %d unique values)\" % (col, len(s)))\n        pre_len = len(df)\n\n        # Merge the one hot columns\n        df = df.merge(one_hot_df, on=[col], how=\"left\")\n        assert len(df) == pre_len\n        print(df.shape)\n    return df\nTrain_Ohe = OHE(cats,Train)\nTest_Ohe = OHE(cats,Test)\n# Test = OHE(\"DAY\",Test)\nprint(Train_Ohe.columns,Train_Ohe.shape)\nTrain_Ohe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"904ffb0d5ce14b3ff833d18d20f71c8bbe78fd1d"},"cell_type":"code","source":"over_col = categorical_columns_features_train\nover_col.append('DAY')\nover_col.append('CONTACT_DATE')\nover_col+=['DEVICE_TYPE_ID__1.0' ,'DEVICE_TYPE_ID__4.0']\nprint (over_col)\n# final_col = [col for col in Test_Ohe.columns if col not in over_col]\n# final_col = ['COM_CAT#2', 'COM_CAT#8','REVENUE','ITC','VAS','RENT_CHANNEL','ROAM','COST','COM_CAT#17','COM_CAT#18','COM_CAT#19','COM_CAT#20','COM_CAT#21','COM_CAT#22','COM_CAT#23','COM_CAT#27','COM_CAT#28','COM_CAT#29','COM_CAT#30','COM_CAT#31','COM_CAT#32','COM_CAT#33']\nfinal_col = ['COM_CAT#2', 'COM_CAT#8','REVENUE','ITC','VAS','RENT_CHANNEL','COST','COM_CAT#20','COM_CAT#21','COM_CAT#22','COM_CAT#23','COM_CAT#27','COM_CAT#28','COM_CAT#29','COM_CAT#30','COM_CAT#31','COM_CAT#32','COM_CAT#33']\n# final_col = ['COM_CAT#2', 'COM_CAT#8','REVENUE','ITC','VAS','RENT_CHANNEL','COST','COM_CAT#20','COM_CAT#23','COM_CAT#27','COM_CAT#29','COM_CAT#30','COM_CAT#31','COM_CAT#32','COM_CAT#33']\n\n\n# final_col.append('SK_ID')\nfinal_col, len(final_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a904d290deee06f3c4e9f8b83dd18c39b1d286d"},"cell_type":"code","source":"# def OHE(col,df):\n#     s = df[col].unique()\n#     print (s)\n\n#     # Create a One Hot Dataframe with 1 row for each unique value\n#     one_hot_df = pd.get_dummies(s, prefix='%s_' % col)\n#     one_hot_df[col] = s\n\n#     print(\"Adding One Hot values for %s (the column has %d unique values)\" % (col, len(s)))\n#     pre_len = len(df)\n\n#     # Merge the one hot columns\n#     df = df.merge(one_hot_df, on=[col], how=\"left\")\n#     assert len(df) == pre_len\n#     print(df.shape)\n#     return df\n# Train = OHE(\"DAY\",Train)\n# Test = OHE(\"DAY\",Test)\n# print(Train.columns,Test.columns)\n# Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52fd62805eecd8c45490a6cf142fa6a5c2b0eb7f"},"cell_type":"code","source":"# Train_X = Train[['SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN','VOICE_DUR_MIN']].values\n# Test_X = Test[['SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN','VOICE_DUR_MIN']].values\n# Train_X = Train[['SUM_MINUTES','SUM_DATA_MB']].values\n# Test_X = Test[['SUM_MINUTES','SUM_DATA_MB']].values\n# Train_X = Train[['DAY__Friday', 'DAY__Monday', 'DAY__Saturday', 'DAY__Sunday', 'DAY__Thursday', 'DAY__Tuesday', 'DAY__Wednesday']].values\n# Test_X = Test[['DAY__Friday', 'DAY__Monday', 'DAY__Saturday', 'DAY__Sunday', 'DAY__Thursday', 'DAY__Tuesday', 'DAY__Wednesday']].values\n# Train_X = Train[['SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN','VOICE_DUR_MIN','DAY__Friday', 'DAY__Monday', 'DAY__Saturday', 'DAY__Sunday', 'DAY__Thursday', 'DAY__Tuesday', 'DAY__Wednesday']].values\n# Test_X = Test[['SUM_MINUTES','SUM_DATA_MB','SUM_DATA_MIN','VOICE_DUR_MIN','DAY__Friday', 'DAY__Monday', 'DAY__Saturday', 'DAY__Sunday', 'DAY__Thursday', 'DAY__Tuesday', 'DAY__Wednesday']].values\n\nTrain_Y = Train_Ohe[['CSI']].values\n# Train_X = Train_Ohe[['SUM_MINUTES','SUM_DATA_MB']].values\n# Test_X = Test_Ohe[['SUM_MINUTES','SUM_DATA_MB']].values\nTrain_X = Train_Ohe[final_col].values\nTest_X = Test_Ohe[final_col].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de7398da53b41f3f297911296b39b3326d4fadb6"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(Train_X, Train_Y, test_size=0.25, random_state=42)\nnp.random.seed(0)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Dense(256, input_dim=len(final_col),activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid')) #sigmoid\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\nmodel.fit(X_train, y_train,\n          epochs=24,\n          batch_size=16)\nscore = model.evaluate(X_test, y_test, batch_size=16)\nprint ('score - ',score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf7bb149868d3251c074c9939cf62de263288f16"},"cell_type":"code","source":"import xgboost\nfrom sklearn.metrics import accuracy_score\n\nparam = {'max_depth': 50, 'objective': 'binary:logistic','eval_metric': 'auc'}\nmodel2 = xgboost.XGBClassifier(**param)\nmodel2.fit(X_train, y_train)\n# make predictions for test data\ny_pred = model2.predict(X_test)\n# predictions = [round(value) for value in y_pred]\npredictions = [value for value in y_pred]\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\nxgboost.plot_importance(model2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10eaef3608f420e363952d1778e363660e806d16"},"cell_type":"code","source":"res1 = model.predict(Test_X, batch_size=16)\nres2 = model2.predict(Test_X)\nres = np.zeros(5221)\nfor i in range (len(res1)):\n    res[i]=(res1[i]+res2[i])/2\nprint (res2.max(),res.max(),res1.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff90c8765171f7743aa5d81b5a3360e783f1030"},"cell_type":"code","source":"sub = pd.DataFrame(res)\nsub.to_csv('subm_ens.csv', header=False, index=False)\n\nsub1 = pd.DataFrame(res1)\nsub1.to_csv('subm_dens.csv', header=False, index=False)\n\nsub2 = pd.DataFrame(res2)\nsub2.to_csv('subm_xgb.csv', header=False, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}